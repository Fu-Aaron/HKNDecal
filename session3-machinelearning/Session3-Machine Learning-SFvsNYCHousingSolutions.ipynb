{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - SF vs NYC Housing \n",
    "#### Going Down the EECS Stack DeCal Spring 2017\n",
    "Data courtesy of [r2d3](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
    "<img src=\"https://grapecollective.com/media/article/image/cache/720x337-center/c/o/comparison.jpg\">\n",
    "\n",
    "In this notebook, we'll explore some ideas behind machine learning using housing data from San Francisco and New York. </br>\n",
    "Each data point corresponds to a house with the following fields:\n",
    "- year_built (int, e.g. 1990)\n",
    "- price_per_sqft (int, dollars)\n",
    "- bath (float)\n",
    "- beds (float)\n",
    "- elevation (int, ft)\n",
    "- price (int, dollars)\n",
    "- in_sf (int, 1 if in sf, 0 otherwise)\n",
    "\n",
    "In the first part of this notebook we'll try to classify houses and predict whether a house is from NYC or SF. In the second part we'll try to regress and predict the prices of the houses.\n",
    "\n",
    "<br />\n",
    "Mathy Notation for later parts:\n",
    "- $n$ denotes the number of data points (houses) \n",
    "- $d$ denotes the number of features \n",
    "- $X$ is an $n \\times d$ matrix, where each row corresponds to a house. $X_i$ means the $i$th row, or the $i$th feature vector.\n",
    "- $y$ is a length $n$ vector, where each index corresponds to a label. $y_i$ means the label for the $i$th house. For part 1 the labels are either $1$ or $0$ for SF and NYC respectively. For part 2 the labels are real numbers denoting housing price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from util3 import extract_cols, visualize_linear_regression, visualize_perceptron, load_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load housing data\n",
    "all_data, features_c, labels_c, features_r, labels_r = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Classification: NYC vs SF\n",
    "In this section, our goal is to learn a model that predicts whether a given house is from SF or from NYC. Our label is \"is_sf\", which is 1 if the house belongs to SF, 0 if NYC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Manual Classification\n",
    "1. Use the cells below to explore statistics about the housing data. Note the mean and range of certain features. Which feature helps differentiating nyc and sf houses the most?\n",
    "2. Use your knowledge about the data to fill in the function \"is_in_sf,\" which takes in a feature dictionary and returns 1 if you think this house belongs in SF, 0 if it belongs to NY\n",
    "3. Test how good your result is. Try to improve your score as much as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_housing_histogram(feature_name):\n",
    "    '''\n",
    "    statistic is either 'mean', 'std', 'min', 'max'\n",
    "    feel free to modify this function to explore other properties about the housing data.\n",
    "    '''\n",
    "    if feature_name not in features_c[0]:\n",
    "        raise ValueError(\"Invalid feature_name!\")\n",
    "        \n",
    "    sf = []\n",
    "    nyc = []\n",
    "    for data in all_data:\n",
    "        if data['in_sf']:\n",
    "            sf.append(data[feature_name])\n",
    "        else:\n",
    "            nyc.append(data[feature_name])\n",
    "    \n",
    "    plt.figure()\n",
    "    bins = np.histogram(np.hstack((sf, nyc)), bins=50)[1]\n",
    "    plt.hist(sf, bins, alpha=0.5, facecolor='red', label='SF')\n",
    "    plt.hist(nyc, bins, alpha=0.5, facecolor='blue', label='NYC')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('number of houses')\n",
    "    plt.title('Histogram of SF and NYC Houses by {}'.format(feature_name))\n",
    "    plt.legend()\n",
    "    \n",
    "    print('SF | mean: {}, std: {}, min: {}, max: {}'.format(np.mean(sf), np.std(sf), min(sf), max(sf)))\n",
    "    print('NYC | mean: {}, std: {}, min: {}, max: {}'.format(np.mean(nyc), np.std(nyc), min(nyc), max(nyc)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) explore the data\n",
    "# available features are price, year_built, bath, beds, elevation, price_per_sqft\n",
    "plot_housing_histogram('elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Implement is_in_sf\n",
    "def is_in_sf(feature):\n",
    "    '''\n",
    "    feature is a dictionary with the following keys: \n",
    "    - 'year_built'\n",
    "    - 'price_per_sqft'\n",
    "    - 'bath'\n",
    "    - 'beds'\n",
    "    - 'elevation'\n",
    "    - 'price'\n",
    "    \n",
    "    return 1 if house is predicted to be in SF, 0 if NYC    \n",
    "    '''\n",
    "    ### Your Code Below ###\n",
    "    return feature['elevation'] > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Test your performance!\n",
    "num_correct = 0\n",
    "sf_but_pred_ny = 0\n",
    "total_num = len(features_c)\n",
    "for i, feature in enumerate(features_c):\n",
    "    prediction_in_sf = is_in_sf(feature)\n",
    "    if prediction_in_sf == labels_c[i]:\n",
    "        num_correct += 1\n",
    "    else:\n",
    "        if labels_c[i] and not prediction_in_sf:\n",
    "            sf_but_pred_ny += 1\n",
    "print(\"Got {:.2f}% correct!\".format(num_correct/1./total_num*100))\n",
    "print(\"Out of incorrect predictions, {:.2f}% were SF houses predicted to be in NYC\".format(\n",
    "                                                                                sf_but_pred_ny/1./(total_num - num_correct)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 The Perceptron Algorithm\n",
    "\n",
    "In this section we will implement the perceptron algorithm, which will learn a linear decision boundary function $f(x)$ of the form:\n",
    "$$\n",
    "f(X_i) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            1 & \\quad w^\\top X_i + b > 0 \\\\\n",
    "            0 & \\quad else\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$\n",
    "You can think of this function as drawing a line in the feature space. If a data point is above this line, we'll say it's from SF. If a data point is below this line, we'll say it's from NYC. In the 1D case where there is only 1 feature used, $w$ would be the slope of the line, and $b$ the y-intercept.\n",
    "\n",
    "<br />\n",
    "\n",
    "Note that $f$ is *parameterized* by $w$ and $b$. So our goal is to find the $w$ and $b$ that best minimizes a *loss* function:\n",
    "$$\n",
    "L(X, y) = \\frac{1}{N} \\sum_{i=1}^{N} (f_{w, b}(X_i) - y_i)^2\n",
    "$$\n",
    "\n",
    "The learning update equations for the perceptron algorithm are:\n",
    "$$\n",
    "error = (w^\\top x + b) - y\n",
    "$$\n",
    "$$\n",
    "w = w + \\alpha * error * x\n",
    "$$\n",
    "$$\n",
    "b = b + \\alpha * error\n",
    "$$\n",
    "\n",
    "<br />\n",
    "The perceptron algorithm has 2 *hyperparameters*: the learning rate ($\\alpha$) and the number of epochs to be trained on. In addition, we can also select a smaller set of features instead of using all of them to learn on (sometimes this performs better). Complete the steps below:\n",
    "1. Implement the perceptron algorithm\n",
    "2. Experiment w/ learning rate and epochs. How do these affect the train and test performance? Why?\n",
    "3. Experiment w/ feature selection. Which features seem to work the best? Why?\n",
    "4. Tweak the above settings to get the best test performance. \n",
    "5. If you used 2 or 3 features, you can run the visualization code to visualize the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def f(w, b, x):\n",
    "    if w.dot(x) + b > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def classification_accuracy(X, y, w, b):\n",
    "    y_pred = [f(w, b, x) for x in X]\n",
    "    return (1 - mean_absolute_error(y_pred, y))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Read this implementation. Try matching it with the pseudocode\n",
    "def perceptron_learn_w_b(X_tr, y_tr, X_t, y_t, epochs, learning_rate, features_to_use=None, vis=False):\n",
    "    '''\n",
    "    Run the perceptron algorithm for epochs iterations\n",
    "    Return w, b\n",
    "    '''\n",
    "    # dimensions\n",
    "    N = X_tr.shape[0] # number of data points we have\n",
    "    d = X_tr.shape[1] # dimension of a feature vector\n",
    "    \n",
    "    # initialize weights\n",
    "    w = np.zeros(d) # a vector of 0's of size d\n",
    "    b = 0 # bias starts at 0\n",
    "    \n",
    "    if vis and d in (2, 3):\n",
    "        fig = plt.figure()\n",
    "    \n",
    "    # perceptron learning algorithm\n",
    "    for t in range(epochs):\n",
    "        for i in range(N):            \n",
    "            x = X_tr[i]\n",
    "            pred_y = f(w, b, x)\n",
    "            error = y_tr[i] - pred_y\n",
    "            \n",
    "            ### begin student code ###\n",
    "            w = w + learning_rate * error * x     \n",
    "            b = b + learning_rate * error\n",
    "            ### end student code ###\n",
    "        \n",
    "        if vis and d in (2, 3):\n",
    "            fig.clf()\n",
    "            visualize_perceptron(features_to_use, X_tr, y_tr, w, b, fig)\n",
    "            fig.canvas.draw()\n",
    "            sleep(1)\n",
    "        \n",
    "        # reporting accuracy\n",
    "        train_accuracy = classification_accuracy(X_tr, y_tr, w, b)\n",
    "        test_accuracy = classification_accuracy(X_t, y_t, w, b)\n",
    "        #clear_output(wait=True)\n",
    "        print('epoch={}/{} | train={:.2f}% | test={:.2f}%'.format(t+1, epochs, train_accuracy, test_accuracy))\n",
    "                \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Choose hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Choose which features to use\n",
    "# available features are 'bath', 'beds', 'year_built', 'price_per_sqft', 'elevation', 'price'\n",
    "# experiment with a subset of these to find what works best\n",
    "features_to_use_c = ['price_per_sqft', 'elevation'] # please use 2 or 3 features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4) Run this cell to train perceptron!\n",
    "index_train_split = int(0.8 * len(features_c))\n",
    "features_c_small = extract_cols(features_c, features_to_use_c)\n",
    "features_c_train_array, features_c_test_array = features_c_small[:index_train_split], features_c_small[index_train_split:]\n",
    "labels_c_train_array, labels_c_test_array = np.array(labels_c[:index_train_split]), np.array(labels_c[index_train_split:])\n",
    "\n",
    "w_c, b_c = perceptron_learn_w_b(features_c_train_array, labels_c_train_array, features_c_test_array, labels_c_test_array, \n",
    "                            10, learning_rate, features_to_use=features_to_use_c, vis=True)\n",
    "print('w is ', w_c, 'b is ', b_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) visualize data and learned decision boundary for 2 or 3 features\n",
    "visualize_perceptron(features_to_use_c, features_c_train_array, labels_c_train_array, w_c, b_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Regression on Housing Price\n",
    "\n",
    "In this section, our goal is to learn a model that predicts house prices. Our label is now \"price\" instead of \"in_sf.\" \"in_sf\" is now included as a feature.\n",
    "\n",
    "Regression, unlike classification, predicts a continuous range of values instead of discrete classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 OLS for Expected House Price\n",
    "\n",
    "In linear regression, we use a linear function to map from input features to output labels. Similar to the perceptron algorithm above, this model has the form:\n",
    "$$\n",
    "y_i = X_i^\\top w\n",
    "$$\n",
    "The new $f$ for regression which outputs the predicted $y$ values will be:\n",
    "$$\n",
    "f(X_i) = X_i^\\top w\n",
    "$$\n",
    "Our loss function will be the same as above:\n",
    "$$\n",
    "L(X, y) = \\frac{1}{N} \\sum_{i=1}^{N} (f_{w}(X_i) - y_i)^2\n",
    "$$\n",
    "\n",
    "We have a closed form solution for this problem. If $X$ is a matrix of features and $y$ the list of labels, then we can write:\n",
    "$$\n",
    "w = (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "\n",
    "To evaluate how good our predictor is, we compute two metrics - mean absolute error and the coefficient of determination (r2 score). Mean absolute error is the average absolute difference of our predicted house price and the true house price. This number however can be difficult to interpret, so we introduce another metric called the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination), or r2 score. R2 scores roughly compute how good a set of predictions are given ground truth data. A higher r2 score means better predictions, and 100% accuracy correspond to an r2 score of 1. \n",
    "\n",
    "Complete the steps below:\n",
    "1. Implement Linear Regression using $b$ as the mean of $y$ and $w$ the pseudoinverse of $X$\n",
    "2. Experiment with which features to use to get the best performance\n",
    "3. Run Linear Regression. Observe results.\n",
    "4. Visualize the linear regression line for when using only 1 feature or 2 features.\n",
    "5. Are the results good or bad? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Implement OLS\n",
    "def linear_regression(X_tr, y_tr, X_t, y_t):\n",
    "    '''\n",
    "    return weight vector w and bias b\n",
    "    hints:\n",
    "    - np.mean(x) returns the mean of x\n",
    "    - np.linalg.pinv returns the pseudoinverse of x\n",
    "    - a.dot(b) or a @ b returns the dot product of a and b\n",
    "    '''\n",
    "    ### begin student code ###\n",
    "    w = np.linalg.inv(X_tr.T @ X_tr).dot(X_tr.T).dot(y_tr)\n",
    "    ### End student code ##\n",
    "    \n",
    "    train_mae = regression_mae(X_tr, y_tr, w)\n",
    "    test_mae = regression_mae(X_t, y_t, w)\n",
    "    \n",
    "    print(\"Train MAE {} | Test MAE {}\".format(train_mae, test_mae))\n",
    "    \n",
    "    return w\n",
    "\n",
    "\n",
    "def regression_mae(X, y, w):\n",
    "    y_pred = X.dot(w)\n",
    "    return mean_absolute_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Choose which features to use\n",
    "# available features are 'bath', 'beds', 'year_built', 'price_per_sqft', 'elevation', 'in_sf'\n",
    "# experiment with a subset of these to find what works best\n",
    "features_to_use_r = ['price_per_sqft', 'elevation']\n",
    "# features_to_use_r = ['bath', 'beds', 'year_built', 'price_per_sqft', 'elevation', 'in_sf']\n",
    "\n",
    "index_train_split = int(0.8 * len(features_r))\n",
    "features_r_small = extract_cols(features_r, features_to_use_r)\n",
    "features_r_biased = np.hstack((features_r_small, np.ones((len(features_r),1))))  # Adding column of ones for bias\n",
    "features_r_train_array, features_r_test_array = features_r_biased[:index_train_split], features_r_biased[index_train_split:]\n",
    "labels_r_train_array, labels_r_test_array = np.array(labels_r[:index_train_split]), np.array(labels_r[index_train_split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Run this cell to run linear regression\n",
    "w_r = linear_regression(features_r_train_array, labels_r_train_array, features_r_test_array, labels_r_test_array)\n",
    "\n",
    "# Computing linear regressor's r2 score using the linear regressor above\n",
    "pred_tr_linear = features_r_train_array.dot(w_r)\n",
    "pred_t_linear = features_r_test_array.dot(w_r)\n",
    "pred_tr_linear_r2 = r2_score(pred_tr_linear, labels_r_train_array)\n",
    "pred_t_linear_r2 = r2_score(pred_t_linear, labels_r_test_array)\n",
    "print(\"Linear Regressor | Train r2 {:.2f}. Test r2 {:.2f}\".format(pred_tr_linear_r2, pred_t_linear_r2))\n",
    "\n",
    "print('w is ', w_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Visualize linear predictor for 1 or 2 features\n",
    "visualize_linear_regression(features_to_use_r, features_r_train_array, labels_r_train_array, w_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 2.2 Regression with Decision Tree\n",
    "\n",
    "The main drawback of linear regression is that it is a model with low expressiveness (or representational power) - it can't fit to complex patterns in data. Another popular method in supervised learning is called Decision Tree. Below we demonstrate fitting this data using decision trees and show the improvements in prediction.\n",
    "\n",
    "<br />\n",
    "Complete the following steps:\n",
    "1. Change the depth hyperparameter and run Decision Tree Regressor\n",
    "2. Compute r2 scores for decision tree\n",
    "3. Slowly increase the depth from:\n",
    "    - What depth achieves the best train performance?\n",
    "    - What depth achieves the best test performance?\n",
    "    - At what depth does the test performance begin to decrease? Why?\n",
    "4. Export and visualize decision tree using dot. Open .dot file, and copy the contents to this [site](http://dreampuf.github.io/GraphvizOnline/) to generate the visualization. Compare results with your neighbors. \n",
    "    - Which features are being split on? \n",
    "    - Which feature is the most important one?\n",
    "    - Are these feature splits expected/surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Train a Decision Tree Regressor\n",
    "depth = 8 # Experiment with this value to see the balance between train and test performance\n",
    "decision_tree = DecisionTreeRegressor(max_depth=depth)\n",
    "features_dt_train, features_dt_test = features_r_small[:index_train_split], features_r_small[index_train_split:]\n",
    "decision_tree.fit(features_dt_train, labels_r_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2) Compute decision tree regressor's MAE and r2 score\n",
    "pred_tr_decisiontree = decision_tree.predict(features_dt_train)\n",
    "pred_t_decisiontree = decision_tree.predict(features_dt_test)\n",
    "pred_tr_decisiontree_r2 = r2_score(pred_tr_decisiontree, labels_r_train_array)\n",
    "pred_t_decisiontree_r2 = r2_score(pred_t_decisiontree, labels_r_test_array)\n",
    "print(\"Decision Tree Regressor | Train MAE {:.2f}. Test MAE {:.2f}\".format(\n",
    "                            mean_absolute_error(pred_tr_decisiontree, labels_r_train_array),\n",
    "                            mean_absolute_error(pred_t_decisiontree, labels_r_test_array)))\n",
    "print(\"Decision Tree Regressor | Train r2 {:.2f}. Test r2 {:.2f}\".format(pred_tr_decisiontree_r2, pred_t_decisiontree_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) export decision tree\n",
    "export_graphviz(decision_tree, out_file='decision_tree_regressor.dot', feature_names=features_to_use_r)\n",
    "\n",
    "# view by entering command: dot -Tpng decision_tree_regressor.dot -o outfile.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
